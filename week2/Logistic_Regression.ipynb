{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTAky_OS1w0P"
      },
      "source": [
        "# Logistic Regression\n",
        "\n",
        "Logistic regression is a process of modeling the probability of a discrete outcome given an input variable. The most common logistic regression models a binary outcome; something that can take two values such as true/false, yes/no, and so on.\n",
        "\n",
        "In this week you will be doing logistic regression on breast cancer dataset using sklearn library. Feel free to create any new functions required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "E56ck0_P2NR9"
      },
      "outputs": [],
      "source": [
        "#importinf libraries\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import datasets\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qojSAol72cmH"
      },
      "source": [
        "Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "_uUSV8Xk2ePh"
      },
      "outputs": [],
      "source": [
        "breast_cancer = datasets.load_breast_cancer()\n",
        "X, y = breast_cancer.data, breast_cancer.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "N6jcbk5g29XW"
      },
      "outputs": [],
      "source": [
        "#spliting data for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)   #because fit has already been run for the training data in the fit_transform. Using that mean and variance only, we fit the test_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIuuOJcJ3sti"
      },
      "source": [
        "Implement Logistic Regression here :)\n",
        "\n",
        "Print the accuracy and cross entropy loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "gBJ6H_ss3yUr"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "  return 1 / (1 + np.exp(-z))\n",
        "\n",
        "\n",
        "class LogisticRegression:\n",
        "    def __init__(self, lr=0.01, iters=1000): #lr (learning rate) & iters (iterations) could be anything of your choice\n",
        "      self.lr, self.iters = lr, iters\n",
        "\n",
        "    def fit(self, X, y):\n",
        "      # self.X, self.y = X, y\n",
        "      #Initialising the weight and bias vectors; m is the number of datapoints, n is the number of parameters\n",
        "      m, n = X.shape\n",
        "      # print(m, n)\n",
        "      w = np.zeros(n)\n",
        "      # print(w.shape)\n",
        "      b = 0\n",
        "      #optimising the cost function\n",
        "      for i in range(self.iters):\n",
        "        y_pred = sigmoid(np.dot(X, w) + b)\n",
        "        dw = np.mean((np.dot((y_pred - y), X)), axis = 0)\n",
        "        db = np.mean(y_pred - y)\n",
        "        w = w - dw * self.lr\n",
        "        b = b - db * self.lr\n",
        "      #setting the values of w and b for the model\n",
        "      self.w = w\n",
        "      self.b = b\n",
        "\n",
        "    def predict(self, X):\n",
        "      self.probability = sigmoid(np.dot(X, self.w) + self.b)\n",
        "      y_pred = np.where(self.probability > 0.5, 1, 0)\n",
        "      return y_pred\n",
        "\n",
        "model = LogisticRegression(lr=0.01, iters=50000)\n",
        "model.fit(X_train, y_train)\n",
        "# print(model.w, model.b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted values:\n",
            " [1 1 0 1 1 0 1 1 0 0 0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 1\n",
            " 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 0\n",
            " 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0\n",
            " 1 1 0]\n",
            "Actual values:\n",
            " [1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1\n",
            " 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 1 0\n",
            " 1 1 1 0 1 0 1 1 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0\n",
            " 1 0 0]\n",
            "Accuracy of the model: 81.57894736842105%\n"
          ]
        }
      ],
      "source": [
        "print(\"Predicted values:\\n\", model.predict(X_test))\n",
        "print(\"Actual values:\\n\", y_test)\n",
        "\n",
        "# accuracy_array = np.bitwise_xor(y_test, model.predict(X_test))\n",
        "matches = y_test == model.predict(X_test)\n",
        "print(\"Accuracy of the model: \", (np.sum(matches)/len(y_test))*100, \"%\", sep=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Binary cross entropy loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Value of cost function: 0.39320560047650693\n"
          ]
        }
      ],
      "source": [
        "#This is the calculation of cost function for the test data\n",
        "def BCELoss(y,y_pred):\n",
        "    return -np.mean(y * np.log(y_pred) + (1-y) * np.log(1-y_pred))\n",
        "\n",
        "print(\"Value of cost function:\", BCELoss(y_test, model.probability))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
